7 Feb 2019

Yilun says he is now using analyse.py to generate computer-only pickle parameters;  then using process_cuts.py (?? right file ) it runs the AI routine of choice with whatever parameters are selected.   Yilun has streamlined Loic's code, too.    This generated the h5 data file which can run in the AI pipeline Yilun earlier created.



----------------------------------------------------------------------------------------------------------------------------------
below this line the entries are in reverse time order:



2/3/2019
  Trying proc_tes_2Feb.py,   as more recent attempts of combining Yilun's tes filtered TOD list with my feature set ran into trouble.  
  In this version of the code, I've got feature1, 2 and 3, plus the relatively new feature5, which is the weird ~60 sec filter in 
calculation.  I'll run this code overnight and generate feature data with which to try analysis.
  RESULT:   code timed out after 4 hours of running.  
  I timed proc_tes_2Feb.py running through all the features listed just above plus the results (using cuts analysis from moby2); 
it comes out to a little over 2 min for the first TOD of the set.     On the basis of this, I'm now trying "len=20" to go through 
20 TODs in batch mode.  This ought to finish in about 45 min.
  This finished fairly promptly;  but the length of the feature output files was screwy.   I deleted these output .npy files and am running this code again.
  Note that if 20 TODs will run in ~45 min., I could manually concoct four or five copies of the code to tackle different sets of 20 TODs each and run them in parallel manually.  This, the analysis code could simply read all the input files and combine the data into the full 70 or 80 TOD or 100 TOD data set.   Better be carefully about the order of reading and such.
  I figured out that I was appending to the feature arrays in the wrong position within the loops in the code.  I think it works now.  Also, the result array was being constructed incorrectly in this code!   yeeech.    ---->>>  nope:  the features are looking ok, but the result_train_tes_3Feb.npy file is too short !!!  More work to do.  :(
    
4 Feb 2019
    proc_tes_2Feb.py is all messed up with indices !   j count runs too big - why?  k count is off -- why ?    
    
6 Feb 2019
    I rewrote the operating parts of proc_tes_2Feb.py and it seems to work now.
    Generated results and feature1, feature2, feature3, feature5 for 5 TODs (I think...  the test set had 1060 samples in it for the following experiments):
NN = 3
1060 samples
True-positives:  22.3 %
True-negatives:  48.4 %
False-positives: 12.6 %
False-negatives: 16.7 %
 
Accuracy:        70.7 %
Precision:       63.8 %
Sensitivity:     57.1 %

NN = 4
1060 samples
True-positives:  16.5 %
True-negatives:  54.0 %
False-positives: 7.1 %
False-negatives: 22.5 %
 
Accuracy:        70.5 %
Precision:       70.0 %
Sensitivity:     42.4 %

NN = 2
1060 samples
True-positives:  15.5 %
True-negatives:  54.2 %
False-positives: 6.8 %
False-negatives: 23.5 %
 
Accuracy:        69.7 %
Precision:       69.5 %
Sensitivity:     39.7 %

Using ONLY feture5: 
1060 samples
True-positives:  22.1 %
True-negatives:  45.3 %
False-positives: 15.8 %
False-negatives: 16.9 %
 
Accuracy:        67.4 %
Precision:       58.4 %
Sensitivity:     56.7 %

----
Back to feat1, feat2, feat3 only
NN = 3
1060 samples
True-positives:  18.3 %
True-negatives:  46.0 %
False-positives: 15.0 %
False-negatives: 20.7 %
 
Accuracy:        64.3 %
Precision:       55.0 %
Sensitivity:     47.0 %

Recap:
Best accuracy =  70.7% with feat1, feat2, feat3, feat5 avail, NN=6
Lowest FP rate =  6.8% with     ""  ,  NN = 2
Lowest FN rate =  16.7%  with    " ",  NN = 3
Best sensitivity =  57.1%  with  " ",  NN= 3






  
  
  
