2/3/2019
  Trying proc_tes_2Feb.py,   as more recent attempts of combining Yilun's tes filtered TOD list with my feature set ran into trouble.  
  In this version of the code, I've got feature1, 2 and 3, plus the relatively new feature5, which is the weird ~60 sec filter in 
calculation.  I'll run this code overnight and generate feature data with which to try analysis.
  RESULT:   code timed out after 4 hours of running.  
  I timed proc_tes_2Feb.py running through all the features listed just above plus the results (using cuts analysis from moby2); 
it comes out to a little over 2 min for the first TOD of the set.     On the basis of this, I'm now trying "len=20" to go through 
20 TODs in batch mode.  This ought to finish in about 45 min.
  This finished fairly promptly;  but the length of the feature output files was screwy.   I deleted these output .npy files and am running this code again.
  Note that if 20 TODs will run in ~45 min., I could manually concoct four or five copies of the code to tackle different sets of 20 TODs each and run them in parallel manually.  This, the analysis code could simply read all the input files and combine the data into the full 70 or 80 TOD or 100 TOD data set.   Better be carefully about the order of reading and such.
  I figured out that I was appending to the feature arrays in the wrong position within the loops in the code.  I think it works now.  Also, the result array was being constructed incorrectly in this code!   yeeech.    ---->>>  nope:  the features are looking ok, but the result_train_tes_3Feb.npy file is too short !!!  More work to do.  :(
    
    




  
  
  
